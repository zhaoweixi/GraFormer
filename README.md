# paper link:
(https://drive.google.com/file/d/17lZP0NsBEKqjR6boDHTAEpKtxYrL2IQc/view?usp=sharing)

# Training & Test
The code for data preprocessing and model evaluation is borrowed from SemGCN.
[garyzhao/SemGCN](https://github.com/garyzhao/SemGCN)


# Pretrain Model:

(baidu: https://pan.baidu.com/s/1fIsCfD80Z_aCB6-5YAdInA?pwd=1234 提取码：1234)

(google: https://drive.google.com/drive/folders/1FOTMAiwCj5YE9hO-GQ1WOECpPpBW974y?usp=sharing)

ckpt_best_gt.pth.tar for 5-layer, 96-dim on h36m ground truth 2D.

ckpt_best_cpn.pth.tar for 6-layer, 128-dim on h36m cpn 2D.

# Citation:
If you find our research is helpful, please remember to cite our paper:
~~~
@inproceedings{zhao2022graformer,
  title={GraFormer: Graph-Oriented Transformer for 3D Pose Estimation},
  author={Zhao, Weixi and Wang, Weiqiang and Tian, Yunjie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20438--20447},
  year={2022}
}
~~~
